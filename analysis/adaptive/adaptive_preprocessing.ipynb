{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing of Adaptive Run Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below are examples of the slow analyses (run in TMUX sessions using ipython) which were performed to generate data for the final analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Analyses to be Run in TMUX Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 100 blocked data for the convergence analysis for all runs\n",
    "import a3fe as a3\n",
    "import pickle\n",
    "from a3fe.analyse.process_grads import get_time_series_multiwindow_mbar as get_ts\n",
    "import os\n",
    "\n",
    "ligs = {\n",
    "    \"T4L\": \"t4l\",\n",
    "    \"MIF\": \"mif_180_anti\",\n",
    "    \"MDM2-PIP2\": \"mdm2_pip2_short\",\n",
    "    \"PDE2A\": \"pde2a_p10\",\n",
    "    \"MDM2-Nutlin\": \"mdm2_nutlin_notprot\",\n",
    "}\n",
    "\n",
    "for lig_dir in ligs.values():\n",
    "    assert os.path.exists(lig_dir), f\"Directory {lig_dir} does not exist\"\n",
    "\n",
    "equil_dgs = {}\n",
    "for lig in ligs:\n",
    "    equil_dgs[lig] = {}\n",
    "    calc = a3.Calculation(base_dir = ligs[lig])\n",
    "    for leg in calc.legs:\n",
    "        equil_dgs[lig][str(leg.leg_type)] = {}\n",
    "        for stage in leg.stages:\n",
    "            equil_dgs[lig][str(leg.leg_type)][str(stage.stage_type)] = {}\n",
    "            dgs, times = get_ts(stage.lam_windows, stage.output_dir)\n",
    "            equil_dgs[lig][str(leg.leg_type)][str(stage.stage_type)][\"dgs\"] = dgs\n",
    "            equil_dgs[lig][str(leg.leg_type)][str(stage.stage_type)][\"times\"] = times\n",
    "    calc._close_logging_handlers()\n",
    "    del(calc)\n",
    "\n",
    "    # Pickle the current data\n",
    "    with open(\"final_analysis/equil_dgs.pkl\", \"wb\") as f:\n",
    "        pickle.dump(equil_dgs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the costs of each leg\n",
    "import a3fe as a3\n",
    "import pickle\n",
    "\n",
    "ligs = {\n",
    "    \"T4L\": \"t4l\",\n",
    "    \"MIF\": \"mif_180_anti\",\n",
    "    \"MDM2-PIP2\": \"mdm2_pip2_short\",\n",
    "    \"PDE2A\": \"pde2a_p10\",\n",
    "    \"MDM2-Nutlin\": \"mdm2_nutlin_notprot\",\n",
    "}\n",
    "\n",
    "costs = {}\n",
    "for lig in ligs:\n",
    "    costs[lig] = {}\n",
    "    calc = a3.Calculation(base_dir = ligs[lig])\n",
    "    for leg in calc.legs:\n",
    "        costs[lig][str(leg.leg_type)] = leg.relative_simulation_cost\n",
    "    calc._close_logging_handlers()\n",
    "    del calc\n",
    "\n",
    "with open(\"final_analysis/costs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(costs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the costs of each leg\n",
    "import a3fe as a3\n",
    "import pickle\n",
    "from typing import List, Tuple, Dict, Callable, Union\n",
    "\n",
    "ligs = {\n",
    "    \"T4L\": \"t4l\",\n",
    "    \"MIF\": \"mif_180_anti\",\n",
    "    \"MDM2-PIP2\": \"mdm2_pip2_short\",\n",
    "    \"PDE2A\": \"pde2a_p10\",\n",
    "    \"MDM2-Nutlin\": \"mdm2_nutlin_notprot\",\n",
    "}\n",
    "def read_equil_data(equil_data_path: str) -> Tuple[float, List[float], List[float]]:\n",
    "    \"\"\"Read the equilibration time, lambda values and free energies from the equilibration data file.\"\"\"\n",
    "    with open(equil_data_path, \"r\") as f:\n",
    "        equil_data = f.readlines()\n",
    "    equil_time = float(equil_data[3].split(\":\")[1].strip().split()[0])\n",
    "    pvalues_and_times_list = eval(equil_data[1].split(\":\")[1].strip())\n",
    "    p_vals = [pvalue for pvalue, _ in pvalues_and_times_list]\n",
    "    times = [time for _, time in pvalues_and_times_list]\n",
    "    return equil_time, p_vals, times\n",
    "\n",
    "# Extract the times and p values from the output text file for each stage for each leg for each system\n",
    "equil_times = {}\n",
    "for lig in ligs:\n",
    "    print(f\"Analysing {lig}\")\n",
    "    equil_times[lig] = {}\n",
    "    calc = a3.Calculation(base_dir = ligs[lig], stream_log_level=logging.CRITICAL)\n",
    "    for leg in calc.legs:\n",
    "        equil_times[lig][str(leg.leg_type)] = {}\n",
    "        for stage in leg.stages:\n",
    "            equil_times[lig][str(leg.leg_type)][str(stage.stage_type)] = {}\n",
    "            equil_data_path = stage.output_dir + \"/check_equil_multiwindow_paired_t.txt\"\n",
    "            equil_time, p_vals, times = read_equil_data(equil_data_path)\n",
    "            # Multiply times by costs to get GPU hours\n",
    "            times = np.array(times) * costs[lig][str(leg.leg_type)]\n",
    "            equil_time = equil_time * costs[lig][str(leg.leg_type)]\n",
    "            equil_times[lig][str(leg.leg_type)][str(stage.stage_type)][\"equil_time\"] = equil_time\n",
    "            equil_times[lig][str(leg.leg_type)][str(stage.stage_type)][\"p_vals\"] = p_vals\n",
    "            equil_times[lig][str(leg.leg_type)][str(stage.stage_type)][\"times\"] = times\n",
    "    calc._close_logging_handlers()\n",
    "    del(calc)\n",
    "\n",
    "    # Write most recent version of the dictionary to a pickle\n",
    "    with open(\"final_analysis/equil_times.pkl\", \"wb\") as f:\n",
    "        pickle.dump(equil_times, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a3fe as a3\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "calc_dirs = {\n",
    "    \"T4L\": {\"adaptive\": \"t4l\", \"non-adaptive\": \"../non_adaptive_final/t4l_30000ps\"},\n",
    "    \"MIF\": {\"adaptive\": \"mif_180_anti\", \"non-adaptive\": \"../non_adaptive_final/mif_180_anti_30000ps\"},\n",
    "    \"MDM2-PIP2\": {\"adaptive\": \"mdm2_pip2_short\", \"non-adaptive\": \"../non_adaptive_final/mdm2_pip2_short_30000ps\"},\n",
    "    \"PDE2A\": {\"adaptive\": \"pde2a_p10\", \"non-adaptive\": \"../non_adaptive_final/pde2a_p10_30000\"},\n",
    "    \"MDM2-Nutlin\": {\"adaptive\": \"mdm2_nutlin_notprot\", \"non-adaptive\": \"../non_adaptive_final/mdm2_nutlin_notprot_30000ps\"},\n",
    "}\n",
    "\n",
    "\n",
    "# Get dictionary of final free energy changes for the 30 ns runs\n",
    "final_dGs_all = {}\n",
    "for system in calc_dirs:\n",
    "    final_dGs_all[system] = {}\n",
    "    for method in calc_dirs[system]:\n",
    "        print(f\"Analysing {system} {method}\")\n",
    "        calc = a3.Calculation(base_dir=calc_dirs[system][method], stream_log_level=logging.CRITICAL)\n",
    "        if calc._delta_g is None:\n",
    "            calc.analyse()\n",
    "        final_dGs_all[system][method] = {}\n",
    "        final_dGs_all[system][method][\"dgs\"] = calc._delta_g\n",
    "        for leg in calc.legs:\n",
    "            print(f\"Analysing {leg.leg_type}\")\n",
    "            final_dGs_all[system][method][str(leg.leg_type)] = {}\n",
    "            final_dGs_all[system][method][str(leg.leg_type)][\"dg\"] = leg._delta_g\n",
    "            for stage in leg.stages:\n",
    "                final_dGs_all[system][method][str(leg.leg_type)][str(stage.stage_type)] = {}\n",
    "                final_dGs_all[system][method][str(leg.leg_type)][str(stage.stage_type)][\"dg\"] = stage._delta_g\n",
    "        calc._dump()\n",
    "        calc._close_logging_handlers()\n",
    "        del(calc)\n",
    "\n",
    "        with open(\"final_analysis/final_dGs_all.pkl\", \"wb\") as f:\n",
    "            pickle.dump(final_dGs_all, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a3fe as a3\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "ligs = {\n",
    "    \"T4L\": \"t4l\",\n",
    "    \"MIF\": \"mif_180_anti\",\n",
    "    \"MDM2-PIP2\": \"mdm2_pip2_short\",\n",
    "    \"PDE2A\": \"pde2a_p10\",\n",
    "    \"MDM2-Nutlin\": \"mdm2_nutlin_notprot\",\n",
    "}\n",
    "\n",
    "lam_vals = {}\n",
    "for lig in ligs:\n",
    "    print(f\"Analysing {lig}\")\n",
    "    lam_vals[lig] = {}\n",
    "    calc = a3.Calculation(base_dir = ligs[lig], stream_log_level=logging.CRITICAL)\n",
    "    for leg in calc.legs:\n",
    "        lam_vals[lig][str(leg.leg_type)] = {}\n",
    "        for stage in leg.stages:\n",
    "            lam_vals[lig][str(leg.leg_type)][str(stage.stage_type)] = stage.lam_vals\n",
    "    calc._close_logging_handlers()\n",
    "    del(calc)\n",
    "\n",
    "    # Write most recent version of the dictionary to a pickle\n",
    "    with open(\"final_analysis/lam_vals.pkl\", \"wb\") as f:\n",
    "        pickle.dump(lam_vals, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a3fe as a3\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "ligs = {\n",
    "    \"T4L\": \"t4l\",\n",
    "    \"MIF\": \"mif_180_anti\",\n",
    "    \"MDM2-PIP2\": \"mdm2_pip2_short\",\n",
    "    \"PDE2A\": \"pde2a_p10\",\n",
    "    \"MDM2-Nutlin\": \"mdm2_nutlin_notprot\",\n",
    "}\n",
    "\n",
    "sampling_times = {}\n",
    "\n",
    "for lig in ligs:\n",
    "    print(f\"Analysing {lig}\")\n",
    "    sampling_times[lig] = {}\n",
    "    calc = a3.Calculation(base_dir = ligs[lig], stream_log_level=logging.CRITICAL)\n",
    "    for leg in calc.legs:\n",
    "        sampling_times[lig][str(leg.leg_type)] = {}\n",
    "        for stage in leg.stages:\n",
    "            sampling_times[lig][str(leg.leg_type)][str(stage.stage_type)] = {}\n",
    "            sampling_times[lig][str(leg.leg_type)][str(stage.stage_type)][\"times\"] = [lam.tot_simtime for lam in stage.lam_windows]\n",
    "            sampling_times[lig][str(leg.leg_type)][str(stage.stage_type)][\"times\"] = [lam.tot_simtime for lam in stage.lam_windows]\n",
    "            sampling_times[lig][str(leg.leg_type)][str(stage.stage_type)][\"equil_times\"] = [lam.equil_time * lam.ensemble_size for lam in stage.lam_windows]\n",
    "            sampling_times[lig][str(leg.leg_type)][str(stage.stage_type)][\"lam_vals\"] = [lam.lam for lam in stage.lam_windows]\n",
    "\n",
    "    calc._close_logging_handlers()\n",
    "    del(calc)\n",
    "\n",
    "    # Write most recent version of the dictionary to a pickle\n",
    "    with open(\"final_analysis/sampling_times.pkl\", \"wb\") as f:\n",
    "        pickle.dump(sampling_times, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a3fe as a3\n",
    "import pickle\n",
    "\n",
    "adaptive_paths = {\n",
    "    \"T4L\": \"t4l\",\n",
    "    \"MIF\": \"mif_180_anti\",\n",
    "    \"MDM2-PIP2\": \"mdm2_pip2_short\",\n",
    "    \"PDE2A\": \"pde2a_p10\",\n",
    "    \"MDM2-Nutlin\": \"mdm2_nutlin_notprot\",\n",
    "}\n",
    "\n",
    "# Dict mapping directory names to calculation names\n",
    "non_adapt_paths = {\n",
    "    \"t4l_0.2\": \"../non_adaptive_final/t4l_200ps\",\n",
    "    \"t4l_6\": \"../non_adaptive_final/t4l_5000ps\",\n",
    "    \"t4l_30\": \"../non_adaptive_final/t4l_30000ps\",\n",
    "    \"mif_0.2\": \"../non_adaptive_final/mif_180_anti_200ps\",\n",
    "    \"mif_6\": \"../non_adaptive_final/mif_180_anti_5000ps\",\n",
    "    \"mif_30\": \"../non_adaptive_final/mif_180_anti_30000ps\",\n",
    "    \"mdm2_nut_0.2\": \"../non_adaptive_final/mdm2_nutlin_notprot_200ps\",\n",
    "    \"mdm2_nut_6\": \"../non_adaptive_final/mdm2_nutlin_notprot_5000ps\",\n",
    "    \"mdm2_nut_30\": \"../non_adaptive_final/mdm2_nutlin_notprot_30000ps\",\n",
    "    \"mdm2_pip_0.2\": \"../non_adaptive_final/mdm2_pip2_short_200ps\",\n",
    "    \"mdm2_pip_6\": \"../non_adaptive_final/mdm2_pip2_short_5000ps\",\n",
    "    \"mdm2_pip_30\": \"../non_adaptive_final/mdm2_pip2_short_30000ps\",\n",
    "    \"pde_0.2\": \"../non_adaptive_final/pde2a_p10_200ps\",\n",
    "    \"pde_6\": \"../non_adaptive_final/pde2a_p10_5000ps\",\n",
    "    \"pde_30\": \"../non_adaptive_final/pde2a_p10_30000\",\n",
    "}\n",
    "\n",
    "non_adapt_ligs = {\n",
    "    \"T4L\": {\"0.2 ns\": \"t4l_0.2\", \"6 ns\": \"t4l_6\", \"30 ns\": \"t4l_30\"},\n",
    "    \"MIF\": {\"0.2 ns\": \"mif_0.2\", \"6 ns\": \"mif_6\", \"30 ns\": \"mif_30\"},\n",
    "    \"MDM2-Nutlin\": {\"0.2 ns\": \"mdm2_nut_0.2\", \"6 ns\": \"mdm2_nut_6\", \"30 ns\": \"mdm2_nut_30\"},\n",
    "    \"MDM2-PIP2\": {\"0.2 ns\": \"mdm2_pip_0.2\", \"6 ns\": \"mdm2_pip_6\", \"30 ns\": \"mdm2_pip_30\"},\n",
    "    \"PDE2A\": {\"0.2 ns\": \"pde_0.2\", \"6 ns\": \"pde_6\", \"30 ns\": \"pde_30\"},\n",
    "}\n",
    "\n",
    "calc_structure = {\"bound\":{\"restrain\":a3.StageType.RESTRAIN, \"discharge\":a3.StageType.DISCHARGE, \"vanish\":a3.StageType.VANISH}, \"free\": {\"discharge\":a3.StageType.DISCHARGE, \"vanish\":a3.StageType.VANISH}}\n",
    "\n",
    "comparitive_conv_data = {}\n",
    "for lig in adaptive_paths:\n",
    "    comparitive_conv_data[lig] = {}\n",
    "    for leg in calc_structure:\n",
    "        comparitive_conv_data[lig][leg] = {}\n",
    "        for stage in calc_structure[leg]:\n",
    "            stage_paths = [\n",
    "                adaptive_paths[lig] + f\"/{leg}/{stage}\",\n",
    "                non_adapt_paths[non_adapt_ligs[lig][\"6 ns\"]] + f\"/{leg}/{stage}\",\n",
    "                non_adapt_paths[non_adapt_ligs[lig][\"30 ns\"]] + f\"/{leg}/{stage}\",\n",
    "            ]\n",
    "            stage_iterator = a3.run._utils.SimulationRunnerIterator(\n",
    "                stage_paths,\n",
    "                a3.Stage, stage_type=calc_structure[leg][stage])\n",
    "            conv_data = a3.analyse.compare.get_comparitive_convergence_data(\n",
    "                stage_iterator,\n",
    "                equilibrated=False,\n",
    "                mode=\"block\"\n",
    "            )\n",
    "            comparitive_conv_data[lig][leg][stage] = {\"Adaptive\":{}, \"6 ns\":{}, \"30 ns\":{}}\n",
    "            for k, label in enumerate([\"Adaptive\", \"6 ns\", \"30 ns\"]):\n",
    "                comparitive_conv_data[lig][leg][stage][label][\"dgs\"] = conv_data[k][0]\n",
    "                comparitive_conv_data[lig][leg][stage][label][\"times\"] = conv_data[k][1]\n",
    "\n",
    "    # Pickle the current data\n",
    "    with open(\"final_analysis/comparitive_conv_data.pkl\", \"wb\") as f:\n",
    "        pickle.dump(comparitive_conv_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a3fe as a3\n",
    "import pickle\n",
    "\n",
    "adaptive_paths = {\n",
    "    \"T4L\": \"t4l\",\n",
    "    \"MIF\": \"mif_180_anti\",\n",
    "    \"MDM2-PIP2\": \"mdm2_pip2_short\",\n",
    "    \"PDE2A\": \"pde2a_p10\",\n",
    "    \"MDM2-Nutlin\": \"mdm2_nutlin_notprot\",\n",
    "}\n",
    "\n",
    "# Dict mapping directory names to calculation names\n",
    "non_adapt_paths = {\n",
    "    \"t4l_0.2\": \"../non_adaptive_final/t4l_200ps\",\n",
    "    \"t4l_6\": \"../non_adaptive_final/t4l_5000ps\",\n",
    "    \"t4l_30\": \"../non_adaptive_final/t4l_30000ps\",\n",
    "    \"mif_0.2\": \"../non_adaptive_final/mif_180_anti_200ps\",\n",
    "    \"mif_6\": \"../non_adaptive_final/mif_180_anti_5000ps\",\n",
    "    \"mif_30\": \"../non_adaptive_final/mif_180_anti_30000ps\",\n",
    "    \"mdm2_nut_0.2\": \"../non_adaptive_final/mdm2_nutlin_notprot_200ps\",\n",
    "    \"mdm2_nut_6\": \"../non_adaptive_final/mdm2_nutlin_notprot_5000ps\",\n",
    "    \"mdm2_nut_30\": \"../non_adaptive_final/mdm2_nutlin_notprot_30000ps\",\n",
    "    \"mdm2_pip_0.2\": \"../non_adaptive_final/mdm2_pip2_short_200ps\",\n",
    "    \"mdm2_pip_6\": \"../non_adaptive_final/mdm2_pip2_short_5000ps\",\n",
    "    \"mdm2_pip_30\": \"../non_adaptive_final/mdm2_pip2_short_30000ps\",\n",
    "    \"pde_0.2\": \"../non_adaptive_final/pde2a_p10_200ps\",\n",
    "    \"pde_6\": \"../non_adaptive_final/pde2a_p10_5000ps\",\n",
    "    \"pde_30\": \"../non_adaptive_final/pde2a_p10_30000\",\n",
    "}\n",
    "\n",
    "non_adapt_ligs = {\n",
    "    \"T4L\": {\"0.2 ns\": \"t4l_0.2\", \"6 ns\": \"t4l_6\", \"30 ns\": \"t4l_30\"},\n",
    "    \"MIF\": {\"0.2 ns\": \"mif_0.2\", \"6 ns\": \"mif_6\", \"30 ns\": \"mif_30\"},\n",
    "    \"MDM2-Nutlin\": {\"0.2 ns\": \"mdm2_nut_0.2\", \"6 ns\": \"mdm2_nut_6\", \"30 ns\": \"mdm2_nut_30\"},\n",
    "    \"MDM2-PIP2\": {\"0.2 ns\": \"mdm2_pip_0.2\", \"6 ns\": \"mdm2_pip_6\", \"30 ns\": \"mdm2_pip_30\"},\n",
    "    \"PDE2A\": {\"0.2 ns\": \"pde_0.2\", \"6 ns\": \"pde_6\", \"30 ns\": \"pde_30\"},\n",
    "}\n",
    "\n",
    "calc_structure = {\"bound\":{\"restrain\":a3.StageType.RESTRAIN, \"discharge\":a3.StageType.DISCHARGE, \"vanish\":a3.StageType.VANISH}, \"free\": {\"discharge\":a3.StageType.DISCHARGE, \"vanish\":a3.StageType.VANISH}}\n",
    "\n",
    "comparitive_conv_data = {}\n",
    "for lig in adaptive_paths:\n",
    "    comparitive_conv_data[lig] = {}\n",
    "    calc_paths = [\n",
    "        adaptive_paths[lig],\n",
    "        non_adapt_paths[non_adapt_ligs[lig][\"6 ns\"]],\n",
    "        non_adapt_paths[non_adapt_ligs[lig][\"30 ns\"]],\n",
    "    ]\n",
    "    calc_iterator = a3.run._utils.SimulationRunnerIterator(\n",
    "        calc_paths,\n",
    "        a3.Calculation)\n",
    "    conv_data = a3.analyse.compare.get_comparitive_convergence_data(\n",
    "        calc_iterator,\n",
    "        equilibrated=False,\n",
    "        mode=\"block\"\n",
    "    )\n",
    "    comparitive_conv_data[lig] = {\"Adaptive\":{}, \"6 ns\":{}, \"30 ns\":{}}\n",
    "    for k, label in enumerate([\"Adaptive\", \"6 ns\", \"30 ns\"]):\n",
    "        comparitive_conv_data[lig][label] = {}\n",
    "        comparitive_conv_data[lig][label][\"dgs\"] = conv_data[k][1]\n",
    "        comparitive_conv_data[lig][label][\"times\"] = conv_data[k][0]\n",
    "\n",
    "    # Pickle the current data\n",
    "    with open(\"final_analysis/comparitive_conv_data_calcs.pkl\", \"wb\") as f:\n",
    "        pickle.dump(comparitive_conv_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparitive_conv_data[\"T4L\"][\"bound\"][\"discharge\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a3fe as a3\n",
    "import pickle\n",
    "\n",
    "with open(\"final_analysis/costs.pkl\", \"rb\") as f:\n",
    "    costs = pickle.load(f)\n",
    "\n",
    "with open(\"final_analysis/comparitive_conv_data.pkl\", \"rb\") as f:\n",
    "    comparitive_conv_data = pickle.load(f)\n",
    "\n",
    "# Convert fractions to GPU hours. For the unequilibrated leg, do this by multiplying\n",
    "# by first converting the fracts to simulation times, then multipling these by the \n",
    "# relative simulation cost * the simulation cost reference of 0.21 hr / ns\n",
    "REF_COST = 0.21 # GPU hours per ns\n",
    "ligs = {\n",
    "    \"T4L\": \"t4l\",\n",
    "    \"MIF\": \"mif_180_anti\",\n",
    "    \"MDM2-PIP2\": \"mdm2_pip2_short\",\n",
    "    \"PDE2A\": \"pde2a_p10\",\n",
    "    \"MDM2-Nutlin\": \"mdm2_nutlin_notprot\",\n",
    "}\n",
    "\n",
    "\n",
    "for lig in comparitive_conv_data:\n",
    "    print(f\"Converting {lig}\")\n",
    "    for leg in comparitive_conv_data[lig]:\n",
    "        leg_enum_str = \"LegType.\" + leg.upper()\n",
    "        cost = REF_COST * costs[lig][leg_enum_str]\n",
    "        for stage in comparitive_conv_data[lig][leg]:\n",
    "            for time in comparitive_conv_data[lig][leg][stage]:\n",
    "                gpu_times = np.array(comparitive_conv_data[lig][leg][stage][time][\"times\"])*cost\n",
    "                comparitive_conv_data[lig][leg][stage][time][\"gpu_times\"] = gpu_times\n",
    "\n",
    "with open(\"final_analysis/comparitive_conv_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(comparitive_conv_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a3fe as a3\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "# Dict mapping directory names to calculation names\n",
    "ligs = {\n",
    "    \"T4L\": \"t4l\",\n",
    "    \"MIF\": \"mif_180_anti\",\n",
    "    \"MDM2-PIP2\": \"mdm2_pip2_short\",\n",
    "    \"PDE2A\": \"pde2a_p10\",\n",
    "    \"MDM2-Nutlin\": \"mdm2_nutlin_notprot\",\n",
    "}\n",
    "\n",
    "dgs_conv = {}\n",
    "\n",
    "# Code to generate dictionary of blocks of free energy changes for each stage for each leg for each time for each system\n",
    "dgs_conv[lig] = {}\n",
    "for time in ligs[lig]:\n",
    "    dgs_conv[lig][time] = {}\n",
    "    print(f\"Analysing {lig} {time}\")\n",
    "    calc = a3.Calculation(base_dir = ligs[lig], stream_log_level=logging.CRITICAL)\n",
    "    for leg in calc.legs:\n",
    "        dgs_conv[lig][time][str(leg.leg_type)] = {}\n",
    "        for stage in leg.stages:\n",
    "            dgs_conv[lig][time][str(leg.leg_type)][str(stage.stage_type)] = {}\n",
    "            fracts = stage._delta_g_convergence_fracts\n",
    "            fracts, dgs = stage.analyse_convergence(mode=\"block\", equilibrated=False)\n",
    "            dgs_conv[lig][time][str(leg.leg_type)][str(stage.stage_type)][\"fracts\"] = fracts\n",
    "            dgs_conv[lig][time][str(leg.leg_type)][str(stage.stage_type)][\"dgs\"] = dgs\n",
    "    calc._close_logging_handlers()\n",
    "    del(calc)\n",
    "\n",
    "    # Write most recent version of the dictionary to a pickle\n",
    "    savename = \"final_analysis/dgs_conv_nonequil.pkl\" \n",
    "    with open(savename, \"wb\") as f:\n",
    "        pickle.dump(dgs_conv, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a3fe as a3\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"final_analysis/costs.pkl\", \"rb\") as f:\n",
    "    costs = pickle.load(f)\n",
    "\n",
    "with open(\"final_analysis/dgs_conv_nonequil.pkl\", \"rb\") as f:\n",
    "    dgs_conv_nonequil = pickle.load(f)\n",
    "\n",
    "# Convert fractions to GPU hours. For the unequilibrated leg, do this by multiplying\n",
    "# by first converting the fracts to simulation times, then multipling these by the \n",
    "# relative simulation cost * the simulation cost reference of 0.21 hr / ns\n",
    "REF_COST = 0.21 # GPU hours per ns\n",
    "ligs = {\n",
    "    \"T4L\": \"t4l\",\n",
    "    \"MIF\": \"mif_180_anti\",\n",
    "    \"MDM2-PIP2\": \"mdm2_pip2_short\",\n",
    "    \"PDE2A\": \"pde2a_p10\",\n",
    "    \"MDM2-Nutlin\": \"mdm2_nutlin_notprot\",\n",
    "}\n",
    "\n",
    "\n",
    "# Convert fractions to GPU hours. For the unequilibrated leg, do this by multiplying\n",
    "# by first converting the fracts to simulation times, then multipling these by the \n",
    "# relative simulation cost * the simulation cost reference of 0.21 hr / ns\n",
    "REF_COST = 0.21 # GPU hours per ns\n",
    "\n",
    "dg_dicts = {\"nonequil\": dgs_conv_nonequil}\n",
    "for dg_type, dg_dict in dg_dicts.items():\n",
    "    for lig in ligs:\n",
    "        print(f\"Converting {lig} {dg_type}\")\n",
    "        calc = a3.Calculation(base_dir = ligs[lig])\n",
    "        for leg in calc.legs:\n",
    "            for stage in leg.stages:\n",
    "                cost = REF_COST * costs[lig][str(leg.leg_type)]\n",
    "                start_time = 0 if dg_type == \"nonequil\" else stage.equil_time * stage.ensemble_size\n",
    "                end_time = stage.tot_simtime\n",
    "                fracts = np.array(dg_dict[lig][str(leg.leg_type)][str(stage.stage_type)][\"fracts\"])\n",
    "                times = ((end_time - start_time) * fracts ) + start_time\n",
    "                gpu_times = times * cost\n",
    "                dg_dict[lig][str(leg.leg_type)][str(stage.stage_type)][\"sim_times\"] = times\n",
    "                dg_dict[lig][str(leg.leg_type)][str(stage.stage_type)][\"gpu_times\"] = gpu_times\n",
    "\n",
    "        calc._close_logging_handlers()\n",
    "        del(calc)\n",
    "\n",
    "with open(\"final_analysis/dgs_conv_nonequil.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dgs_conv_nonequil, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a3fe as a3\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "with open(\"final_analysis/costs.pkl\", \"rb\") as f:\n",
    "    costs = pickle.load(f)\n",
    "\n",
    "\n",
    "# Convert fractions to GPU hours. For the unequilibrated leg, do this by multiplying\n",
    "# by first converting the fracts to simulation times, then multipling these by the \n",
    "# relative simulation cost * the simulation cost reference of 0.21 hr / ns\n",
    "REF_COST = 0.21 # GPU hours per ns\n",
    "ligs = {\n",
    "    \"T4L\": \"t4l\",\n",
    "    \"MIF\": \"mif_180_anti\",\n",
    "    \"MDM2-PIP2\": \"mdm2_pip2_short\",\n",
    "    \"PDE2A\": \"pde2a_p10\",\n",
    "    \"MDM2-Nutlin\": \"mdm2_nutlin_notprot\",\n",
    "}\n",
    "\n",
    "\n",
    "REF_COST = 0.21 # GPU hours per ns\n",
    "\n",
    "adaptive_paths = {\n",
    "    \"T4L\": \"t4l\",\n",
    "    \"MIF\": \"mif_180_anti\",\n",
    "    \"MDM2-PIP2\": \"mdm2_pip2_short\",\n",
    "    \"PDE2A\": \"pde2a_p10\",\n",
    "    \"MDM2-Nutlin\": \"mdm2_nutlin_notprot\",\n",
    "}\n",
    "\n",
    "# Dict mapping directory names to calculation names\n",
    "non_adapt_paths = {\n",
    "    \"t4l_0.2\": \"../non_adaptive_final/t4l_200ps\",\n",
    "    \"t4l_6\": \"../non_adaptive_final/t4l_5000ps\",\n",
    "    \"t4l_30\": \"../non_adaptive_final/t4l_30000ps\",\n",
    "    \"mif_0.2\": \"../non_adaptive_final/mif_180_anti_200ps\",\n",
    "    \"mif_6\": \"../non_adaptive_final/mif_180_anti_5000ps\",\n",
    "    \"mif_30\": \"../non_adaptive_final/mif_180_anti_30000ps\",\n",
    "    \"mdm2_nut_0.2\": \"../non_adaptive_final/mdm2_nutlin_notprot_200ps\",\n",
    "    \"mdm2_nut_6\": \"../non_adaptive_final/mdm2_nutlin_notprot_5000ps\",\n",
    "    \"mdm2_nut_30\": \"../non_adaptive_final/mdm2_nutlin_notprot_30000ps\",\n",
    "    \"mdm2_pip_0.2\": \"../non_adaptive_final/mdm2_pip2_short_200ps\",\n",
    "    \"mdm2_pip_6\": \"../non_adaptive_final/mdm2_pip2_short_5000ps\",\n",
    "    \"mdm2_pip_30\": \"../non_adaptive_final/mdm2_pip2_short_30000ps\",\n",
    "    \"pde_0.2\": \"../non_adaptive_final/pde2a_p10_200ps\",\n",
    "    \"pde_6\": \"../non_adaptive_final/pde2a_p10_5000ps\",\n",
    "    \"pde_30\": \"../non_adaptive_final/pde2a_p10_30000\",\n",
    "}\n",
    "\n",
    "non_adapt_ligs = {\n",
    "    \"T4L\": {\"0.2 ns\": \"t4l_0.2\", \"6 ns\": \"t4l_6\", \"30 ns\": \"t4l_30\"},\n",
    "    \"MIF\": {\"0.2 ns\": \"mif_0.2\", \"6 ns\": \"mif_6\", \"30 ns\": \"mif_30\"},\n",
    "    \"MDM2-Nutlin\": {\"0.2 ns\": \"mdm2_nut_0.2\", \"6 ns\": \"mdm2_nut_6\", \"30 ns\": \"mdm2_nut_30\"},\n",
    "    \"MDM2-PIP2\": {\"0.2 ns\": \"mdm2_pip_0.2\", \"6 ns\": \"mdm2_pip_6\", \"30 ns\": \"mdm2_pip_30\"},\n",
    "    \"PDE2A\": {\"0.2 ns\": \"pde_0.2\", \"6 ns\": \"pde_6\", \"30 ns\": \"pde_30\"},\n",
    "}\n",
    "\n",
    "calc_structure = {\"bound\":{\"restrain\":a3.StageType.RESTRAIN, \"discharge\":a3.StageType.DISCHARGE, \"vanish\":a3.StageType.VANISH}, \"free\": {\"discharge\":a3.StageType.DISCHARGE, \"vanish\":a3.StageType.VANISH}}\n",
    "\n",
    "gpu_times = {}\n",
    "for lig in adaptive_paths:\n",
    "    gpu_times[lig] = {\"Adaptive\":0, \"0.2 ns\":0,\"6 ns\":0, \"30 ns\":0}\n",
    "    for sim_label in gpu_times[lig]:\n",
    "        calc_path = adaptive_paths[lig] if sim_label == \"Adaptive\" else non_adapt_paths[non_adapt_ligs[lig][sim_label]]\n",
    "        calc = a3.Calculation(base_dir = calc_path, stream_log_level=logging.CRITICAL)\n",
    "        for leg in calc.legs:\n",
    "            cost = REF_COST * costs[lig][str(leg.leg_type)]\n",
    "            gpu_hr = cost*leg.tot_simtime\n",
    "            gpu_times[lig][sim_label] += gpu_hr\n",
    "        calc._close_logging_handlers()\n",
    "        del(calc)\n",
    "\n",
    "    # Pickle the current data\n",
    "    with open(\"final_analysis/gpu_times.pkl\", \"wb\") as f:\n",
    "        pickle.dump(gpu_times, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensequil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
