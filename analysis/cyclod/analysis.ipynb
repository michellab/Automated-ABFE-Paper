{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Adaptive Runs vs Non-Adaptive Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a3fe as a3 \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams, rcParamsDefault\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "from sklearn import metrics\n",
    "rcParams.update(rcParamsDefault)\n",
    "plt.style.use(\"seaborn-v0_8-colorblind\")\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath}')\n",
    "from typing import List, Tuple, Dict, Callable, Union, Optional, Any, Dict\n",
    "%matplotlib inline\n",
    "from scipy.stats import linregress, kruskal, t, sem, wilcoxon\n",
    "from matplotlib import gridspec\n",
    "import pymbar\n",
    "print(pymbar.version.version)\n",
    "import logging\n",
    "\n",
    "ligs = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "adaptive_paths = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "non_adapt_paths = {lig: f\"../non_adaptive/{adapt_path}_5000ps\" for lig, adapt_path in adaptive_paths.items()}\n",
    "\n",
    "REF_COST = 0.21 # GPU hours per ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Analyses to be Run in TMUX Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the Results of the Slow Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\n",
    "    \"comparitive_conv_data\",\n",
    "    \"overall_costs\",\n",
    "    \"costs\",\n",
    "    \"equil_dgs\",\n",
    "    \"final_dGs_all\",\n",
    "    \"total_costs\",\n",
    "    \"overall_results_alibay\",\n",
    "    \"restraint_corrections\",\n",
    "    \"restraint_dicts\",\n",
    "    \"lam_vals\",\n",
    "    \"sampling_times\",\n",
    "    \"sampling_times_nonadapt\",\n",
    "    \"dgs_conv_adaptive_nonequil\",\n",
    "    \"dgs_conv_non_adaptive_nonequil\",\n",
    "]\n",
    "\n",
    "file_paths = {name: f\"final_analysis/{name}.pkl\" for name in file_names}\n",
    "\n",
    "for var, file in file_paths.items():\n",
    "    with open(file, \"rb\") as f:\n",
    "        globals()[var] = pickle.load(f)\n",
    "\n",
    "final_dgs_all = final_dGs_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline of Notebook\n",
    "\n",
    "- Table of results (adaptive, non-adaptive, and Alibay results)\n",
    "- Statistical tests comparing results\n",
    "- Equilibration analysis\n",
    "- Selection of lambda windows\n",
    "- Sampling time allocations + costs\n",
    "- Convergence plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Overall Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dgs = pd.read_csv(\"final_analysis/exp_dgs.csv\", index_col=1)\n",
    "exp_dgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_95_ci(data: np.ndarray) -> Tuple[float, float]:\n",
    "    \"\"\"Get the 95% confidence interval for a given array of data using scipy.stats.sem\"\"\"\n",
    "    mean_free_energy = np.mean(data)\n",
    "    conf_int = t.interval(\n",
    "        0.95,\n",
    "        len(data) - 1,\n",
    "        mean_free_energy,\n",
    "        scale=sem(data),\n",
    "    )[1] - mean_free_energy # 95 % C.I.\n",
    "    return conf_int\n",
    "    \n",
    "symmetry_corrections = {lig: 0.0 for lig in ligs}\n",
    "\n",
    "exp_dgs = pd.read_csv(\"final_analysis/exp_dgs.csv\", index_col=1)\n",
    "\n",
    "\n",
    "results_summary = {}\n",
    "for system in final_dgs_all:\n",
    "    results_summary[system] = {}\n",
    "    for method in final_dgs_all[system]:\n",
    "        dgs = np.array(final_dgs_all[system][method][\"dgs\"])\n",
    "        dg_tot = np.mean(dgs) + symmetry_corrections[system]\n",
    "        dg_err = get_95_ci(dgs)\n",
    "        result_str = f\"{dg_tot:.2f}\" + r\" $\\pm$ \" + f\"{dg_err:.2f}\"\n",
    "        results_summary[system][method] = result_str\n",
    "\n",
    "    # Add the Alibay value\n",
    "    alibay_dg = overall_results_alibay[system][\"mean_dG\"]\n",
    "    alibay_err = overall_results_alibay[system][\"95_ci\"]\n",
    "    alibay_str = f\"{alibay_dg:.2f}\" + r\" $\\pm$ \" + f\"{alibay_err:.2f}\"\n",
    "    results_summary[system][\"Alibay\"] = alibay_str\n",
    "\n",
    "    # Add the experimental value\n",
    "    exp_dg = exp_dgs.loc[f\"lig_{system}\", \"exp_dg\"]\n",
    "    exp_err = exp_dgs.loc[f\"lig_{system}\", \"exp_er\"]\n",
    "    exp_str = f\"{exp_dg:.2f}\" + r\" $\\pm$ \" + f\"{exp_err:.2f}\"\n",
    "    results_summary[system][r\"Exp. $\\Delta G^o_\\textrm{Bind}$\"] = exp_str\n",
    "\n",
    "# Turn results summary into a dataframe, setting the first colum name to \"ligand\"\n",
    "# Add an extra row at the top with \"adaptive\" spanning two columnrs and \"non-adaptive\" spanning two columns\n",
    "results_summary_df = pd.DataFrame(results_summary).T\n",
    "# Change column names to \"Adaptive\" and \"Non-adaptive 5 ns\"\n",
    "results_summary_df.columns = [\"Adaptive\", \"Non-adaptive 5 ns\", \"Alibay\", r\"Exp. $\\Delta G^o_\\textrm{Bind}$\"]\n",
    "# Change the indexes to f\"Ligand {index}\"\n",
    "results_summary_df.index = [f\"Ligand {index}\" for index in results_summary_df.index]\n",
    "results_summary_df.to_latex(\"final_analysis/results_summary.tex\", escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed results table\n",
    "\n",
    "# Repeat as above, but make a much more explicit table including all contributions to the final free energy change and the\n",
    "# symmetry corrections. Make the systems the columns and the rows the different contributions to the free energy change\n",
    "final_dGs = final_dgs_all\n",
    "results_summary_detailed = {}\n",
    "for system in final_dGs:\n",
    "    for time in final_dGs[system]:\n",
    "        title = f\"{system} {time}\"\n",
    "        results_summary_detailed[title] = {}\n",
    "        for leg_type in final_dGs[system][time]:\n",
    "            if leg_type == \"dgs\":\n",
    "                continue\n",
    "            leg_name = leg_type.split(\".\")[1].capitalize()\n",
    "            for stage_type in final_dGs[system][time][leg_type]:\n",
    "                if stage_type == \"dg\":\n",
    "                    continue\n",
    "                stage_name = stage_type.split(\".\")[1].capitalize()\n",
    "                dgs = np.array(final_dGs[system][time][leg_type][stage_type][\"dg\"])\n",
    "                dg_tot = np.mean(dgs)\n",
    "                dg_err = get_95_ci(dgs)\n",
    "                result_str = f\"{dg_tot:.2f}\" + r\" $\\pm$ \" + f\"{dg_err:.2f}\"\n",
    "                results_summary_detailed[title][f\"{leg_name} {stage_name}\"] = result_str\n",
    "        # Add in symmetry correction and restraint correction, along with experimental results\n",
    "        restraint_corr = restraint_corrections[system]\n",
    "        restraint_corr_str = f\"{restraint_corr:.2f}\"\n",
    "        results_summary_detailed[title][\"Restraint Correction\"] = restraint_corr_str\n",
    "        symmetry_corr = symmetry_corrections[system]\n",
    "        symmetry_corr_str = f\"{symmetry_corr:.2f}\"\n",
    "        results_summary_detailed[title][\"Symmetry Correction\"] = symmetry_corr_str\n",
    "        exp_dg = exp_dgs.loc[f\"lig_{system}\", \"exp_dg\"]\n",
    "        exp_err = exp_dgs.loc[f\"lig_{system}\", \"exp_er\"]\n",
    "        exp_str = f\"{exp_dg:.2f}\" + r\" $\\pm$ \" + f\"{exp_err:.2f}\"\n",
    "        results_summary_detailed[title][r\"Exp. $\\Delta G^o_\\textrm{Bind}$\"] = exp_str\n",
    "\n",
    "results_summary_detailed_df = pd.DataFrame(results_summary_detailed).T\n",
    "results_summary_detailed_df.to_latex(\"final_analysis/results_summary_detailed.tex\", escape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of sampling times\n",
    "\n",
    "df_total_costs = pd.DataFrame(total_costs)\n",
    "df_total_costs.index = [f\"Ligand {index}\" for index in df_total_costs.index]\n",
    "# Add a total row\n",
    "df_total_costs.loc[\"Total\"] = df_total_costs.sum()\n",
    "# Round to integers and do not display any decimal places\n",
    "df_total_costs = df_total_costs.round(0)\n",
    "df_total_costs = df_total_costs.astype(int)\n",
    "df_total_costs.to_latex(\"final_analysis/total_costs.tex\", escape=False)\n",
    "df_total_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restraint parameters\n",
    "\n",
    "# Double all the force constants, because of the definition in SOMD (kx rather than 0.5kx^2)\n",
    "for system in restraint_dicts:\n",
    "    force_constants = restraint_dicts[system][\"force_constants\"]\n",
    "    for key in force_constants:\n",
    "        force_constants[key] *= 2\n",
    "\n",
    "# Now turn the restraints dict into a nice dataframe\n",
    "restraint_df_dict = {}\n",
    "for system in restraint_dicts:\n",
    "    restraint_df_dict[system] = {}\n",
    "    for index in restraint_dicts[system][\"anchor_points\"]:\n",
    "        restraint_df_dict[system][index] = str(round(restraint_dicts[system][\"anchor_points\"][index]))\n",
    "    for equil_val in restraint_dicts[system][\"equilibrium_values\"]:\n",
    "        restraint_df_dict[system][equil_val] = f'{restraint_dicts[system][\"equilibrium_values\"][equil_val]:.2f}'\n",
    "    for force_const in restraint_dicts[system][\"force_constants\"]:\n",
    "        restraint_df_dict[system][force_const] = f'{restraint_dicts[system][\"force_constants\"][force_const]:.2f}'\n",
    "\n",
    "replace_dict = {\"r0\": r\"$r_0$ / $\\mathrm{\\AA}$\", \n",
    "                \"thetaA0\": r\"$\\theta_{\\mathrm{A}0}$ / $\\mathrm{\\AA}$\", \n",
    "                \"thetaB0\": r\"$\\theta_{\\mathrm{B}0}$ / Rad\", \n",
    "                \"phiA0\": r\"$\\phi_{\\mathrm{A}0}$ / Rad\", \n",
    "                \"phiB0\": r\"$\\phi_{\\mathrm{B}0}$ / Rad\", \n",
    "                \"phiC0\": r\"$\\phi_{\\mathrm{C}0}$ / Rad\",\n",
    "                \"kr\": r\"$k_r$ / kcal mol$^{-1}$ $\\mathrm{\\AA}^{-2}$\", \n",
    "                \"kthetaA\": r\"$k_{\\theta \\mathrm{A}}$ / kcal mol$^{-1}$ $\\mathrm{Rad}^{-2}$\", \n",
    "                \"kthetaB\": r\"$k_{\\theta \\mathrm{B}}$ / kcal mol$^{-1}$ $\\mathrm{Rad}^{-2}$\", \n",
    "                \"kphiA\": r\"$k_{\\phi \\mathrm{A}}$ / kcal mol$^{-1}$ $\\mathrm{Rad}^{-2}$\", \n",
    "                \"kphiB\": r\"$k_{\\phi \\mathrm{B}}$ / kcal mol$^{-1}$ $\\mathrm{Rad}^{-2}$\",\n",
    "                \"kphiC\": r\"$k_{\\phi \\mathrm{C}}$ / kcal mol$^{-1}$ $\\mathrm{Rad}^{-2}$\"}\n",
    "\n",
    "# Create the dataframe\n",
    "restraint_df = pd.DataFrame(restraint_df_dict)\n",
    "# Replace names using the replace_dict\n",
    "restraint_df = restraint_df.rename(columns=replace_dict, index=replace_dict)\n",
    "# Save,making sure not to truncate the label units in the column names\n",
    "with pd.option_context(\"max_colwidth\", 1000):\n",
    "    restraint_df.to_latex(\"final_analysis/restraint_params.tex\", escape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Correlation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(all_results: pd.DataFrame) -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Compute statistics for the passed results, generating 95 % C.I.s\n",
    "    by bootstrapping.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_results : pd.DataFrame\n",
    "        The dataframe containing all results.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Dict[str, List[float]]\n",
    "        A dictionary of the computed statistics, and their upper and lower\n",
    "        confidence bounds.\n",
    "    \"\"\"\n",
    "\n",
    "    # This will hold metric: [value, upper_err, lower_er]\n",
    "    results = {\"r\": [], \"r2\": [], \"mue\": [], \"rmse\": [], \"rho\": [], \"tau\": []}\n",
    "\n",
    "    # Get the bootstrapped results\n",
    "    n_bootstrap = 10000\n",
    "    bootstrapped_exp_dg, bootstrapped_calc_dg = get_bootstrapped_results(\n",
    "        all_results=all_results, n_bootstrap=n_bootstrap\n",
    "    )\n",
    "\n",
    "    # For each metric, calculate i) over the actual data ii) overall bootstrapped data and extract stats\n",
    "    for metric in results:\n",
    "        results[metric].append(\n",
    "            compute_statistic(all_results[\"exp_dg\"], all_results[\"calc_dg\"], metric)\n",
    "        )\n",
    "        bootstrapped_metric = np.zeros([n_bootstrap])\n",
    "        for i in range(n_bootstrap):\n",
    "            bootstrapped_metric[i] = compute_statistic(\n",
    "                bootstrapped_exp_dg[i], bootstrapped_calc_dg[i], metric\n",
    "            )\n",
    "        percentiles = np.percentile(bootstrapped_metric, [5, 95])  # 95 % C.I.s\n",
    "        results[metric].append(percentiles[0])\n",
    "        results[metric].append(percentiles[1])\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_bootstrapped_results(\n",
    "    all_results: pd.DataFrame, n_bootstrap: int = 1000\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Return n_bootstrap bootstrapped versions of the original experimental\n",
    "    and calculated free energies.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_results : pd.DataFrame\n",
    "        The dataframe containing all results.\n",
    "    n_bootstrap : int, optional, default = 1000\n",
    "        Number of boostrap iterations to perform\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boostrapped_exp_dg: np.ndarray\n",
    "        The bootstrapped experimental free energy changes\n",
    "    bootstrapped_calc_dg: np_ndarray\n",
    "        The bootstrapped calculated free energy changes\n",
    "    \"\"\"\n",
    "    exp_dg = all_results[\"exp_dg\"]\n",
    "    calc_dg = all_results[\"calc_dg\"]\n",
    "    exp_sem = all_results[\"exp_er\"] / 1.96\n",
    "    calc_sem = all_results[\"calc_er\"] / 1.96\n",
    "\n",
    "    # Check that the data passed are of the same length\n",
    "    if len(exp_dg) != len(calc_dg):\n",
    "        raise ValueError(\n",
    "            \"The lengths of the calculated and experimental free energy values must match\"\n",
    "        )\n",
    "    n_samples = len(exp_dg)\n",
    "\n",
    "    bootstrapped_exp_dg = np.zeros([n_bootstrap, n_samples])\n",
    "    bootstrapped_calc_dg = np.zeros([n_bootstrap, n_samples])\n",
    "    for i in range(n_bootstrap):\n",
    "        # Ensure we use same indices for the experimental and calculated results to avoid mixing\n",
    "        # results\n",
    "        indices = np.random.choice(np.arange(n_samples), size=n_samples, replace=True)\n",
    "        bootstrapped_exp_dg[i] = np.array(\n",
    "            [np.random.normal(loc=exp_dg[i], scale=exp_sem[i]) for i in indices]\n",
    "        )\n",
    "        bootstrapped_calc_dg[i] = np.array(\n",
    "            [np.random.normal(loc=calc_dg[i], scale=calc_sem[i]) for i in indices]\n",
    "        )\n",
    "\n",
    "    return bootstrapped_exp_dg, bootstrapped_calc_dg\n",
    "\n",
    "\n",
    "def compute_statistic(exp_dg: pd.Series, calc_dg: pd.Series, statistic: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute the desired statistic for one set of experimental and\n",
    "    calculated values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    exp_dg : pd.Series\n",
    "        The experimental free energies\n",
    "    calc_dg : pd.Series\n",
    "        The calculated free energies\n",
    "    statistic : str\n",
    "        The desired statistic to be calculated, from \"r\", \"mue\", \"rmse\"\n",
    "        \"rho\", or \"tau\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The desired statistic.\n",
    "    \"\"\"\n",
    "    # Check that requested metric is implemented\n",
    "    allowed_stats = [\"r\", \"r2\", \"mue\", \"rmse\", \"rho\", \"tau\"]\n",
    "    if statistic not in allowed_stats:\n",
    "        raise ValueError(\n",
    "            f\"Statistic must be one of {allowed_stats} but was {statistic}\"\n",
    "        )\n",
    "\n",
    "    if statistic == \"r\":\n",
    "        return stats.pearsonr(exp_dg, calc_dg)[0]\n",
    "    if statistic == \"r2\":\n",
    "        m, c, r, p, sem = stats.linregress(exp_dg, calc_dg)\n",
    "        return r**2\n",
    "    if statistic == \"mue\":\n",
    "        return metrics.mean_absolute_error(exp_dg, calc_dg)\n",
    "    if statistic == \"rmse\":\n",
    "        return np.sqrt(metrics.mean_squared_error(exp_dg, calc_dg))\n",
    "    if statistic == \"rho\":\n",
    "        return stats.spearmanr(exp_dg, calc_dg)[0]\n",
    "    if statistic == \"tau\":\n",
    "        return stats.kendalltau(exp_dg, calc_dg)[0]\n",
    "\n",
    "\n",
    "def plot_against_exp(\n",
    "    all_results: pd.DataFrame,\n",
    "    offset: bool = False,\n",
    "    stats: Optional[Dict] = None,\n",
    "    x_label: str = r\"Experimental $\\Delta G^o_{\\mathrm{Bind}}$ / kcal mol$^{-1}$\",\n",
    "    y_label: str = r\"Calculated $\\Delta G^o_{\\mathrm{Bind}}$ / kcal mol$^{-1}$\",\n",
    ") -> Tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"\n",
    "    Plot all results from a set of calculations against the\n",
    "    experimental values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_results : pd.DataFrame\n",
    "        A DataFrame containing the experimental and calculated\n",
    "        free energy changes and errors.\n",
    "    offset: bool, Optional, Default = False\n",
    "        Whether the calculated absolute binding free energies have been\n",
    "        offset so that the mean experimental and calculated values are the same.\n",
    "    stats: Dict, Optional, Default = None\n",
    "        A dictionary of statistics, obtained using analyse.analyse_set.compute_stats\n",
    "    x_label: str, Optional, Default = r\"Experimental $\\Delta G^o_{\\mathrm{Bind}}$ / kcal mol$^{-1}$\"\n",
    "        The label for the x-axis\n",
    "    y_label: str, Optional, Default = r\"Calculated $\\Delta G^o_{\\mathrm{Bind}}$ / kcal mol$^{-1}$\"]\n",
    "        The label for the y-axis\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[plt.Figure, plt.Axes]\n",
    "        The figure and axes of the plot.\n",
    "    \"\"\"\n",
    "    # Check that the correct columns have been supplied\n",
    "    required_columns = [\n",
    "        \"calc_base_dir\",\n",
    "        \"exp_dg\",\n",
    "        \"exp_er\",\n",
    "        \"calc_cor\",\n",
    "        \"calc_dg\",\n",
    "        \"calc_er\",\n",
    "    ]\n",
    "    # if list(all_results.columns) != required_column:\n",
    "    #     raise ValueError(\n",
    "    #         f\"The experimental values file must have the columns {required_columns} but has the columns {all_results.columns}\"\n",
    "    #     )\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    ax.errorbar(\n",
    "        x=all_results[\"exp_dg\"],\n",
    "        y=all_results[\"calc_dg\"],\n",
    "        xerr=all_results[\"exp_er\"],\n",
    "        yerr=all_results[\"calc_er\"],\n",
    "        ls=\"none\",\n",
    "        c=\"black\",\n",
    "        capsize=2,\n",
    "        lw=0.5,\n",
    "    )\n",
    "    ax.scatter(x=all_results[\"exp_dg\"], y=all_results[\"calc_dg\"], s=50, zorder=100)\n",
    "    ax.set_ylim([-18, 0])\n",
    "    ax.set_xlim([-18, 0])\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    # 1 kcal mol-1\n",
    "    ax.fill_between(\n",
    "        x=[-25, 0],\n",
    "        y2=[-24, 1],\n",
    "        y1=[-26, -1],\n",
    "        lw=0,\n",
    "        zorder=-10,\n",
    "        alpha=0.5,\n",
    "        color=\"darkorange\",\n",
    "    )\n",
    "    # 2 kcal mol-1\n",
    "    ax.fill_between(\n",
    "        x=[-25, 0],\n",
    "        y2=[-23, 2],\n",
    "        y1=[-27, -2],\n",
    "        lw=0,\n",
    "        zorder=-10,\n",
    "        color=\"darkorange\",\n",
    "        alpha=0.2,\n",
    "    )\n",
    "\n",
    "    # Add text, including number of ligands and stats if supplied\n",
    "    n_ligs = len(all_results[\"calc_dg\"])\n",
    "    ax.text(0.03, 0.95, f\"{n_ligs} ligands\", transform=ax.transAxes)\n",
    "    if stats:\n",
    "        stats_text = \"\"\n",
    "        for stat, label in zip(\n",
    "            [\"r2\", \"mue\", \"rho\", \"tau\"],\n",
    "            [\"R$^2$\", \"MUE\", r\"Spearman $\\rho$\", r\"Kendall $\\tau$\"],\n",
    "        ):\n",
    "            stats_text += f\"{label}: {stats[stat][0]:.2f}$^{{{stats[stat][2]:.2f}}}_{{{stats[stat][1]:.2f}}}$\\n\"\n",
    "        ax.text(0.65, 0, stats_text, transform=ax.transAxes)\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data into right format. We need a dataframe with columns \"exp_dg\", \"calc_dg\", \"exp_er\", \"calc_er\"\n",
    "# Get the results for Alibay\n",
    "alibay_results_for_plot = {}\n",
    "for lig in overall_results_alibay:\n",
    "    alibay_results_for_plot[lig] = {}\n",
    "    alibay_results_for_plot[lig][\"exp_dg\"] = exp_dgs.loc[f\"lig_{lig}\", \"exp_dg\"]\n",
    "    alibay_results_for_plot[lig][\"exp_er\"] = exp_dgs.loc[f\"lig_{lig}\", \"exp_er\"]\n",
    "    alibay_results_for_plot[lig][\"calc_dg\"] = overall_results_alibay[lig][\"mean_dG\"]\n",
    "    alibay_results_for_plot[lig][\"calc_er\"] = overall_results_alibay[lig][\"95_ci\"]\n",
    "alibay_results_for_plot_df = pd.DataFrame(alibay_results_for_plot).T\n",
    "\n",
    "# Get the results for the non-adaptive 5 ns\n",
    "non_adaptive_results_for_plot = {}\n",
    "for lig in final_dGs_all:\n",
    "    non_adaptive_results_for_plot[lig] = {}\n",
    "    non_adaptive_results_for_plot[lig][\"exp_dg\"] = exp_dgs.loc[f\"lig_{lig}\", \"exp_dg\"]\n",
    "    non_adaptive_results_for_plot[lig][\"exp_er\"] = exp_dgs.loc[f\"lig_{lig}\", \"exp_er\"]\n",
    "    non_adaptive_results_for_plot[lig][\"calc_dg\"] = np.mean(final_dGs_all[lig][\"non_adaptive\"][\"dgs\"])\n",
    "    non_adaptive_results_for_plot[lig][\"calc_er\"] = get_95_ci(final_dGs_all[lig][\"non_adaptive\"][\"dgs\"])\n",
    "    \n",
    "non_adaptive_results_for_plot_df = pd.DataFrame(non_adaptive_results_for_plot).T\n",
    "\n",
    "# Get the results for the adaptive\n",
    "adaptive_results_for_plot = {}\n",
    "for lig in final_dGs_all:\n",
    "    adaptive_results_for_plot[lig] = {}\n",
    "    adaptive_results_for_plot[lig][\"exp_dg\"] = exp_dgs.loc[f\"lig_{lig}\", \"exp_dg\"]\n",
    "    adaptive_results_for_plot[lig][\"exp_er\"] = exp_dgs.loc[f\"lig_{lig}\", \"exp_er\"]\n",
    "    adaptive_results_for_plot[lig][\"calc_dg\"] = np.mean(final_dGs_all[lig][\"adaptive\"][\"dgs\"])\n",
    "    adaptive_results_for_plot[lig][\"calc_er\"] = get_95_ci(final_dGs_all[lig][\"adaptive\"][\"dgs\"])\n",
    "adaptive_results_for_plot_df = pd.DataFrame(adaptive_results_for_plot).T\n",
    "\n",
    "# Make a fake df to compare adaptive and non-adaptive where the \"experimental\" values are the non-adaptive values\n",
    "# and the \"calculated\" values are the adaptive values\n",
    "adaptive_vs_non_adaptive_results_for_plot = {}\n",
    "for lig in final_dGs_all:\n",
    "    adaptive_vs_non_adaptive_results_for_plot[lig] = {}\n",
    "    adaptive_vs_non_adaptive_results_for_plot[lig][\"exp_dg\"] = non_adaptive_results_for_plot[lig][\"calc_dg\"]\n",
    "    adaptive_vs_non_adaptive_results_for_plot[lig][\"exp_er\"] = non_adaptive_results_for_plot[lig][\"calc_er\"]\n",
    "    adaptive_vs_non_adaptive_results_for_plot[lig][\"calc_dg\"] = adaptive_results_for_plot[lig][\"calc_dg\"]\n",
    "    adaptive_vs_non_adaptive_results_for_plot[lig][\"calc_er\"] = adaptive_results_for_plot[lig][\"calc_er\"]\n",
    "adaptive_vs_non_adaptive_results_for_plot_df = pd.DataFrame(adaptive_vs_non_adaptive_results_for_plot).T\n",
    "\n",
    "\n",
    "def print_stats(stats):\n",
    "    for stat in stats:\n",
    "        print(f\"{stat}: {stats[stat][0]:.2f} ({stats[stat][1]:.2f}, {stats[stat][2]:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for Alibay results\n",
    "stats_alibay = compute_stats(alibay_results_for_plot_df)\n",
    "print_stats(stats_alibay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_against_exp(alibay_results_for_plot_df, stats=stats_alibay)\n",
    "fig.savefig(\"final_analysis/alibay_results.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_non_adaptive = compute_stats(non_adaptive_results_for_plot_df)\n",
    "print_stats(stats_non_adaptive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_against_exp(non_adaptive_results_for_plot_df, stats=stats_non_adaptive)\n",
    "fig.savefig(\"final_analysis/non_adaptive_results.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_adaptive = compute_stats(adaptive_results_for_plot_df)\n",
    "print_stats(stats_adaptive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_against_exp(adaptive_results_for_plot_df, stats=stats_adaptive)\n",
    "fig.savefig(\"final_analysis/adaptive_results.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the comparison between the adaptive and non-adaptive runs\n",
    "stats_adaptive_vs_non_adaptive = compute_stats(adaptive_vs_non_adaptive_results_for_plot_df)\n",
    "print_stats(stats_adaptive_vs_non_adaptive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plot_against_exp(adaptive_vs_non_adaptive_results_for_plot_df, stats=stats_adaptive_vs_non_adaptive, \n",
    "                           x_label=r\"Non-adaptive $\\Delta G^o_{\\mathrm{Bind}}$ / kcal mol$^{-1}$\",\n",
    "                           y_label=r\"Adaptive $\\Delta G^o_{\\mathrm{Bind}}$ / kcal mol$^{-1}$\",\n",
    "                           )\n",
    "fig.savefig(\"final_analysis/adaptive_vs_non_adaptive_results.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make df of all stats\n",
    "stats_dfs = {\"Alibay\": stats_alibay, \"Non-adaptive\": stats_non_adaptive, \"Adaptive\": stats_adaptive, \"Adaptive vs Non-adaptive\": stats_adaptive_vs_non_adaptive}\n",
    "overall_stats_data = {}\n",
    "for name, stats in stats_dfs.items():\n",
    "    overall_stats_data[name] = {}\n",
    "    for stat in stats:\n",
    "        overall_stats_data[name][stat] = f\"{stats[stat][0]:.2f} ({stats[stat][1]:.2f}, {stats[stat][2]:.2f})\"\n",
    "overall_stats_df = pd.DataFrame(overall_stats_data)\n",
    "\n",
    "# Rename the rows to make them look nice\n",
    "overall_stats_df.index = [\"$r$\", \"$r^2$\", \"MUE\", \"RMSE\", r\"Spearman $\\rho$\", r\"Kendall $\\tau$\"]\n",
    "\n",
    "# Save to latex\n",
    "overall_stats_df.to_latex(\"final_analysis/overall_stats.tex\", escape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if errors are significantly different between the Alibay and non-adaptive runs\n",
    "# Use paired non-parametric test\n",
    "from scipy.stats import wilcoxon\n",
    "res = wilcoxon(alibay_results_for_plot_df[\"calc_er\"], non_adaptive_results_for_plot_df[\"calc_er\"])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for difference in offset between non-adaptive and Alibay results\n",
    "# Get dfs of the differences to experiment\n",
    "diff_alibay = alibay_results_for_plot_df[\"calc_dg\"] - alibay_results_for_plot_df[\"exp_dg\"]\n",
    "diff_non_adaptive = non_adaptive_results_for_plot_df[\"calc_dg\"] - non_adaptive_results_for_plot_df[\"exp_dg\"]\n",
    "\n",
    "# Use a Wilcoxon signed-rank test\n",
    "res = wilcoxon(diff_alibay, diff_non_adaptive)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for difference in offset between adaptive and non-adaptive results\n",
    "# Get dfs of the differences to experiment\n",
    "diff_adaptive = adaptive_results_for_plot_df[\"calc_dg\"] - adaptive_results_for_plot_df[\"exp_dg\"]\n",
    "diff_non_adaptive = non_adaptive_results_for_plot_df[\"calc_dg\"] - non_adaptive_results_for_plot_df[\"exp_dg\"]\n",
    "\n",
    "# Use a Wilcoxon signed-rank test\n",
    "res = wilcoxon(diff_adaptive, diff_non_adaptive)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for difference in error between adaptive and non-adaptive results\n",
    "res = wilcoxon(adaptive_results_for_plot_df[\"calc_er\"], non_adaptive_results_for_plot_df[\"calc_er\"])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every stage for every system, plot the lambda values vs lambda index and show a dotted line on x = y\n",
    "fig, axs = plt.subplots(3, 9, figsize = (28, 9))\n",
    "for i, lig in enumerate(ligs):\n",
    "    for j, leg in enumerate(lam_vals[lig]):\n",
    "        for k, stage in enumerate(lam_vals[lig][\"LegType.BOUND\"]):\n",
    "            if k == 0 and leg == \"LegType.FREE\":\n",
    "                continue\n",
    "            stage_str = stage.split(\".\")[1].lower().capitalize()\n",
    "            leg_str = leg.split(\".\")[1].lower().capitalize()\n",
    "            lambda_idx = list(range(len(lam_vals[lig][leg][stage])))\n",
    "            linear = np.linspace(0, 1, len(lambda_idx))\n",
    "            lam_vals_local = lam_vals[lig][leg][stage]\n",
    "            axs[k, i].plot(lambda_idx, lam_vals_local, label = leg_str, marker = \"o\")\n",
    "            axs[k, i].plot(lambda_idx, linear, linestyle = \"--\", color = \"black\")\n",
    "            axs[k, i].set_title(f\"{lig} {stage_str}\")\n",
    "            axs[k, i].set_xlabel(\"$\\lambda$ index\")\n",
    "            axs[k, i].set_ylabel(\"$\\lambda$ value\")\n",
    "            # Add text stating the number of windows\n",
    "            offset = 0.05 if leg == \"LegType.FREE\" else 0.1\n",
    "            axs[k, i].text(0.6, offset, f\"No. windows {leg_str}: {len(lam_vals_local)}\", transform = axs[k, i].transAxes, horizontalalignment = \"center\", verticalalignment = \"center\")\n",
    "\n",
    "# Add a legend to the figure, off to the right hand side of all the plots\n",
    "axs[1,8].legend(bbox_to_anchor = (1.05, 0.5), loc = \"center left\", borderaxespad = 0)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"final_analysis/lambda_values.png\", dpi = 600, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Time Allocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 9, figsize = (30, 17), dpi = 600)\n",
    "for i, lig in enumerate(ligs):\n",
    "    for j, leg in enumerate(sampling_times[lig]):\n",
    "        for k, stage in enumerate(sampling_times[lig][leg]):\n",
    "            stage_str = stage\n",
    "            leg_str = leg\n",
    "            times = sampling_times[lig][leg][stage][\"times\"]\n",
    "            times = np.array(times) * costs[lig][leg] * REF_COST\n",
    "            equil_times = sampling_times[lig][leg][stage][\"equil_times\"]\n",
    "            equil_times = np.array(equil_times) * costs[lig][leg] * REF_COST\n",
    "            lam_vals_local = sampling_times[lig][leg][stage][\"lam_vals\"]\n",
    "            # Bar plots for sampling times\n",
    "            ax = axs[k + 3*j, i]\n",
    "            # Get reasonable width for bars\n",
    "            width = 0.6 / len(lam_vals_local)\n",
    "            ax.bar(lam_vals_local, times, label = \"Total sampling time\", edgecolor = \"black\", width = width)\n",
    "            # Plot the equilibration times\n",
    "            ax.bar(lam_vals_local, equil_times, label = \"Equilibration time\", edgecolor = \"black\", width = width, hatch = \"///////\")\n",
    "            ax.set_title(f\"{lig} {leg_str} {stage_str}\")\n",
    "            ax.set_xlabel(\"$\\lambda$\")\n",
    "            ax.set_ylabel(\"GPU Hours\")\n",
    "\n",
    "# Create a legend for the figure to the right of all the plots\n",
    "axs[2,8].legend(bbox_to_anchor = (1.05, 0.5), loc = \"center left\", borderaxespad = 0)\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"final_analysis/sampling_times.png\", dpi = 600, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar plot of costs\n",
    "costs_df = pd.DataFrame(costs)\n",
    "# Nice black outline round bars\n",
    "costs_df.plot.bar(figsize = (10, 5), rot = 0, xlabel = \"Leg\", ylabel = \"Relative cost\", title = \"Relative cost of each leg\", edgecolor = \"black\")\n",
    "# Save figure\n",
    "plt.savefig(\"final_analysis/costs.png\", dpi = 600, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All similar, as expected, so just get the mean cost for each leg\n",
    "costs_df.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a coarser summary of sampling time allocation - just show the total sampling time for each stage for each sytem.\n",
    "# Put everything on a single bar plot. Use the code above as a starting point.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4), dpi=600)\n",
    "x = np.arange(len(sampling_times))\n",
    "width = 0.2\n",
    "# Plot bound and free next to each other\n",
    "for i, stage in enumerate(sampling_times[\"2\"][\"bound\"]):\n",
    "    # Get single colour\n",
    "    color = ax._get_lines.get_next_color()\n",
    "    tot_times_bound = [np.sum(sampling_times[system][\"bound\"][stage][\"times\"])*costs[system][\"bound\"]*REF_COST for system in sampling_times]\n",
    "    ax.bar(x + (i * width), tot_times_bound, width, label=f\"Bound {stage}\", edgecolor=\"k\", alpha=1, color=color)\n",
    "    if stage != \"restrain\":\n",
    "        tot_times_free = [np.sum(sampling_times[system][\"free\"][stage][\"times\"])*costs[system][\"free\"]*REF_COST for system in sampling_times]\n",
    "        ax.bar(x + (i * width), tot_times_free, width, label=f\"Free {stage}\", edgecolor=\"k\", alpha=1, color=color, hatch=\"///////\")\n",
    "\n",
    "ax.set_xticks(x + width)\n",
    "x_labels = []\n",
    "for system in sampling_times:\n",
    "    x_labels.append(system)\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.set_ylabel(\"Total Sampling Time / GPU Hours\")\n",
    "# Put label off to right of plot\n",
    "ax.legend(bbox_to_anchor=(1.03, 0.7))\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"final_analysis/sampling_times_summary.png\", bbox_inches=\"tight\", dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4), dpi=600)\n",
    "x = np.arange(len(sampling_times))\n",
    "width = 0.2\n",
    "# Plot bound and free next to each other\n",
    "for i, stage in enumerate(sampling_times[\"2\"][\"bound\"]):\n",
    "    # Get single colour\n",
    "    n_windows = np.array([len(sampling_times[system][\"bound\"][stage][\"times\"]) for system in sampling_times])\n",
    "    color = ax._get_lines.get_next_color()\n",
    "    tot_times_bound = [np.sum(sampling_times[system][\"bound\"][stage][\"times\"])*costs[system][\"bound\"]*REF_COST for system in sampling_times]\n",
    "    tot_times_bound_per_window = tot_times_bound / n_windows\n",
    "    ax.bar(x + (i * width), tot_times_bound_per_window, width, label=f\"Bound {stage}\", edgecolor=\"k\", alpha=1, color=color)\n",
    "    if stage != \"restrain\":\n",
    "        tot_times_free = [np.sum(sampling_times[system][\"free\"][stage][\"times\"])*costs[system][\"free\"]*REF_COST for system in sampling_times]\n",
    "        tot_times_free_per_window = tot_times_free / n_windows\n",
    "        ax.bar(x + (i * width), tot_times_free_per_window, width, label=f\"Free {stage}\", edgecolor=\"k\", alpha=1, color=color, hatch=\"///////\")\n",
    "\n",
    "ax.set_xticks(x + width)\n",
    "x_labels = []\n",
    "for system in sampling_times:\n",
    "    x_labels.append(system)\n",
    "ax.set_xticklabels(x_labels)\n",
    "ax.set_ylabel(\"Total Sampling Time per Window / GPU Hours\")\n",
    "# Put label off to right of plot\n",
    "ax.legend(bbox_to_anchor=(1.03, 0.7))\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"final_analysis/sampling_times_summary_per_window.png\", bbox_inches=\"tight\", dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots of Free Energy vs Sampling Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_times_non_adaptive = sampling_times_nonadapt\n",
    "\n",
    "def plot_dgs_conv(ax: plt.axes, dgs: np.ndarray,times: np.ndarray, system: str, label: str) -> None:\n",
    "    # Plot the mean free energy\n",
    "    mean_free_energy = np.mean(dgs, axis=0)\n",
    "    ax.plot(times, mean_free_energy, label=label)\n",
    "    # Calculate the 95 % CI with scipy\n",
    "    conf_int = (\n",
    "    t.interval(\n",
    "        0.95,\n",
    "        len(dgs) - 1,\n",
    "        mean_free_energy,\n",
    "        scale=sem(dgs),\n",
    "    )[1]\n",
    "    - mean_free_energy\n",
    "    )  # 95 % C.I.\n",
    "    # Fill between the upper and lower bounds of the 95 % CI\n",
    "    ax.fill_between(\n",
    "        times,\n",
    "        mean_free_energy - conf_int,\n",
    "        mean_free_energy + conf_int,\n",
    "        alpha=0.2,\n",
    "    )\n",
    "    # Label the plot\n",
    "    ax.set_xlabel(\"GPU Hours\")\n",
    "    ax.set_ylabel(r\"$\\Delta G$ / kcal mol$^{-1}$\")\n",
    "    ax.set_title(f\"Lig {system}\")\n",
    "    ax.legend()\n",
    "    # Ensure that the bottom of the scale is 0\n",
    "    plt.tight_layout()\n",
    "\n",
    "def plot_cis_conv_all(dg_dict_nonadapt: Dict, dg_dict_adapt: Dict, scale:bool=False) -> Tuple[plt.Figure, plt.Axes]:\n",
    "    \"\"\"Plot the change in the 95 % CIs for each system\"\"\"\n",
    "    n_systems = len(dg_dict_nonadapt)\n",
    "    n_cols = 5\n",
    "    n_rows = int(np.ceil(n_systems / n_cols))\n",
    "    fig, axs = plt.subplots(n_rows, n_cols, figsize=(20, 8))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for dict_type, dg_dict in {\"Adaptive\": dg_dict_adapt, \"Non-Adaptive\": dg_dict_nonadapt}.items():\n",
    "        samp_times = sampling_times if dict_type == \"Adaptive\" else sampling_times_non_adaptive\n",
    "        for i, lig in enumerate(ligs):\n",
    "            overall_dgs = np.zeros_like(dg_dict[lig][\"LegType.BOUND\"][\"StageType.DISCHARGE\"][\"dgs\"])\n",
    "            overall_times = np.zeros(overall_dgs.shape[1])\n",
    "            for leg_name, leg in dg_dict[lig].items():\n",
    "                leg_label = leg_name.split(\".\")[1].lower()\n",
    "                dg_multiplier = 1 if leg_label == \"free\" else -1\n",
    "                cost = costs[lig][leg_label] * REF_COST \n",
    "                for stage_name in leg:\n",
    "                    stage_label = stage_name.split(\".\")[1].lower()\n",
    "                    stage_dgs = leg[stage_name][\"dgs\"] * dg_multiplier\n",
    "                    tot_time = np.sum(samp_times[lig][leg_label][stage_label][\"times\"]) * costs[lig][leg_label] * REF_COST\n",
    "                    stage_times = np.array(leg[stage_name][\"fracts\"]) * tot_time\n",
    "                    overall_dgs += stage_dgs\n",
    "                    overall_times += stage_times\n",
    "            \n",
    "            # Add the restraint corrections\n",
    "            overall_dgs -= restraint_corrections[lig]\n",
    "\n",
    "            plot_dgs_conv(axs[i], overall_dgs, overall_times, lig, dict_type)\n",
    "\n",
    "    # Delete unused axes\n",
    "    for i in range(n_systems, n_rows * n_cols):\n",
    "        fig.delaxes(axs[i])\n",
    "        \n",
    "    return fig, axs\n",
    "\n",
    "\n",
    "fig, axs = plot_cis_conv_all(dgs_conv_adaptive_nonequil, dgs_conv_non_adaptive_nonequil)\n",
    "fig.savefig(\"final_analysis/cyclod_dgs_conv_overall.png\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensequil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
