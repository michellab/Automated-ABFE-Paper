{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of Data from Adaptive Runs vs Non-Adaptive Runs\n",
    "\n",
    "The cells below are examples of the slow analyses (generally run in TMUX sessions using ipython) which were performed to generate data for the final analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e991d4d5f0614819bebd5d26e5ca36c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rdkit:Enabling RDKit 2022.09.1 jupyter extensions\n",
      "WARNING:root:Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.5.dev-Unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3067038/951591603.py:10: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use(\"seaborn-colorblind\")\n"
     ]
    }
   ],
   "source": [
    "import a3fe as a3 \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams, rcParamsDefault\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "from sklearn import metrics\n",
    "rcParams.update(rcParamsDefault)\n",
    "plt.style.use(\"seaborn-colorblind\")\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath}')\n",
    "from typing import List, Tuple, Dict, Callable, Union, Optional, Any, Dict\n",
    "%matplotlib inline\n",
    "from scipy.stats import linregress, kruskal, t, sem, wilcoxon\n",
    "from matplotlib import gridspec\n",
    "import pymbar\n",
    "print(pymbar.version.version)\n",
    "import logging\n",
    "\n",
    "ligs = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "adaptive_paths = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "non_adapt_paths = {lig: f\"../non_adaptive/{adapt_path}_5000ps\" for lig, adapt_path in adaptive_paths.items()}\n",
    "\n",
    "REF_COST = 0.21 # GPU hours per ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Analyses to be Run in TMUX Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in tmux ipython session\n",
    "\n",
    "import a3fe as a3\n",
    "import pickle\n",
    "\n",
    "adaptive_paths = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "non_adapt_paths = {lig: f\"../non_adaptive/{adapt_path}_5000ps\" for lig, adapt_path in adaptive_paths.items()}\n",
    "\n",
    "# Compare convergence of the overall adaptive and non-adaptive simulations\n",
    "comparitive_conv_data = {}\n",
    "\n",
    "for lig in adaptive_paths:\n",
    "    comparitive_conv_data[lig] = {}\n",
    "    calc_iterator = a3.run._utils.SimulationRunnerIterator(\n",
    "        [adaptive_paths[lig], non_adapt_paths[lig]],\n",
    "        a3.Calculation\n",
    "    )\n",
    "\n",
    "    conv_data = a3.analyse.compare.get_comparitive_convergence_data(\n",
    "        calc_iterator,\n",
    "        equilibrated=False,\n",
    "        mode=\"block\"\n",
    "    )\n",
    "\n",
    "    for k, label in enumerate([\"Adaptive\", \"Non-adaptive\"]):\n",
    "        comparitive_conv_data[lig][label] = {\"dgs\": conv_data[k][1], \"times\": conv_data[k][0]}\n",
    "\n",
    "\n",
    "    # Pickle the current data\n",
    "    with open(\"final_analysis/comparitive_conv_data.pkl\", \"wb\") as f:\n",
    "        pickle.dump(comparitive_conv_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 100 blocked data for the convergence analysis for all runs\n",
    "import a3fe as a3\n",
    "import pickle\n",
    "from EnsEquil.analyse.process_grads import get_time_series_multiwindow_mbar as get_ts\n",
    "\n",
    "ligs = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "equil_dgs = {}\n",
    "for lig in ligs:\n",
    "    equil_dgs[lig] = {}\n",
    "    calc = a3.Calculation(base_dir = ligs[lig])\n",
    "    for leg in calc.legs:\n",
    "        leg_str = str(leg.leg_type).split(\".\")[-1].lower()\n",
    "        equil_dgs[lig][leg_str] = {}\n",
    "        for stage in leg.stages:\n",
    "            stage_str = str(stage.stage_type).split(\".\")[-1].lower()\n",
    "            equil_dgs[lig][leg_str][stage_str] = {}\n",
    "            dgs, times = get_ts(stage.lam_windows, stage.output_dir, equilibrated=False)\n",
    "            equil_dgs[lig][leg_str][stage_str][\"dgs\"] = dgs\n",
    "            equil_dgs[lig][leg_str][stage_str][\"times\"] = times\n",
    "    calc._close_logging_handlers()\n",
    "    del(calc)\n",
    "\n",
    "    # Pickle the current data\n",
    "    with open(\"final_analysis/equil_dgs.pkl\", \"wb\") as f:\n",
    "        pickle.dump(equil_dgs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a3fe as a3\n",
    "import pickle\n",
    "from a3fe.analyse.process_grads import get_time_series_multiwindow_mbar as get_ts\n",
    "\n",
    "ligs = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "overall_costs = {\"Adaptive\":{}, \"Non-adaptive\":{}}\n",
    "# Get the costs of each leg\n",
    "costs = {}\n",
    "for lig in ligs:\n",
    "    costs[lig] = {}\n",
    "    calc = a3.Calculation(base_dir = ligs[lig])\n",
    "    for leg in calc.legs:\n",
    "        costs[lig][str(leg.leg_type)] = leg.relative_simulation_cost\n",
    "    calc._close_logging_handlers()\n",
    "    del calc\n",
    "\n",
    "with open(\"final_analysis/costs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(costs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall costs from costs - weight according to simulation time\n",
    "import a3fe as a3\n",
    "import pickle\n",
    "from a3fe.analyse.process_grads import get_time_series_multiwindow_mbar as get_ts\n",
    "\n",
    "ligs = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "with open(\"final_analysis/costs.pkl\", \"rb\") as f:\n",
    "    costs = pickle.load(f)\n",
    "\n",
    "overall_costs = {\"Adaptive\":{}, \"Non-adaptive\":{}}\n",
    "for lig in comparitive_conv_data:\n",
    "    for method in comparitive_conv_data[lig]:\n",
    "        base_dirs = adaptive_paths if method == \"Adaptive\" else non_adapt_paths\n",
    "        # Get the overall cost as a weighted sum \n",
    "        bound_cost = costs[lig][\"bound\"]\n",
    "        free_cost = costs[lig][\"free\"]\n",
    "        calc = a3.Calculation(base_dir = base_dirs[lig])\n",
    "        simtime_bound = calc.legs[0].tot_simtime\n",
    "        simtime_free = calc.legs[1].tot_simtime\n",
    "        calc._close_logging_handlers()\n",
    "        del(calc)\n",
    "        overall_cost = (bound_cost*simtime_bound + free_cost*simtime_free) / (simtime_bound + simtime_free)\n",
    "        overall_costs[method][lig] = overall_cost\n",
    "\n",
    "with open(\"final_analysis/overall_costs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(overall_costs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the results\n",
    "\n",
    "import a3fe as a3\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "with open(\"costs.pkl\", \"rb\") as f:\n",
    "    costs = pickle.load(f)\n",
    "\n",
    "ligs = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "adaptive_paths = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "non_adapt_paths = {lig: f\"../non_adaptive/{adapt_path}_5000ps\" for lig, adapt_path in adaptive_paths.items()}\n",
    "\n",
    "path_dicts = {\"adaptive\": adaptive_paths, \"non_adaptive\": non_adapt_paths}\n",
    "final_dGs_all = {}\n",
    "for system in ligs:\n",
    "    final_dGs_all[system] = {}\n",
    "    for method in path_dicts:\n",
    "        print(f\"Analysing {system} {method}\")\n",
    "        calc = a3.Calculation(base_dir=path_dicts[method][system], stream_log_level=logging.CRITICAL)\n",
    "        final_dGs_all[system][method] = {}\n",
    "        final_dGs_all[system][method][\"dgs\"] = calc._delta_g\n",
    "        for leg in calc.legs:\n",
    "            print(f\"Analysing {leg.leg_type}\")\n",
    "            final_dGs_all[system][method][str(leg.leg_type)] = {}\n",
    "            final_dGs_all[system][method][str(leg.leg_type)][\"dg\"] = leg._delta_g\n",
    "            for stage in leg.stages:\n",
    "                final_dGs_all[system][method][str(leg.leg_type)][str(stage.stage_type)] = {}\n",
    "                final_dGs_all[system][method][str(leg.leg_type)][str(stage.stage_type)][\"dg\"] = stage._delta_g\n",
    "        calc._close_logging_handlers()\n",
    "        del(calc)\n",
    "\n",
    "        with open(\"final_analysis/final_dGs_all.pkl\", \"wb\") as f:\n",
    "            pickle.dump(final_dGs_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total costs of all runs\n",
    "\n",
    "import a3fe as a3\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "with open(\"costs.pkl\", \"rb\") as f:\n",
    "    costs = pickle.load(f)\n",
    "\n",
    "REF_COST = 0.21 # GPU hours per ns\n",
    "\n",
    "ligs = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "adaptive_paths = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "non_adapt_paths = {lig: f\"../non_adaptive/{adapt_path}_5000ps\" for lig, adapt_path in adaptive_paths.items()}\n",
    "# Restraint corrections and restraint parameters\n",
    "\n",
    "import a3fe as a3\n",
    "import pickle\n",
    "\n",
    "ligs = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "# Get the restraint corrections for each system\n",
    "restraint_corrections = {}\n",
    "restraint_dicts = {}\n",
    "for lig in ligs:\n",
    "    print(f\"Analysing {lig}\")\n",
    "    calc = a3.Calculation(base_dir = ligs[lig])\n",
    "    restr_corr = calc.legs[0].restraints[0].getCorrection().value()\n",
    "    restraint_corrections[lig] = restr_corr\n",
    "    print(f\"Getting restraint parameters for {lig}\")\n",
    "    restr = calc.legs[0].restraints[0]\n",
    "    restr_dict = eval(calc.legs[0].restraints[0].toString(\"SOMD\").split(\"=\")[1])\n",
    "    restraint_dicts[lig] = restr_dict\n",
    "    calc._close_logging_handlers()\n",
    "    del(calc)\n",
    "\n",
    "with open(\"final_analysis/restraint_corrections.pkl\", \"wb\") as f:\n",
    "    pickle.dump(restraint_corrections, f)\n",
    "\n",
    "with open(\"final_analysis/restraint_dicts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(restraint_dicts, f)\n",
    "\n",
    "path_dicts = {\"adaptive\": adaptive_paths, \"non_adaptive\": non_adapt_paths}\n",
    "total_costs = {}\n",
    "for method in path_dicts:\n",
    "    total_costs[method] = {}\n",
    "    for system in ligs:\n",
    "        print(f\"Analysing {system} {method}\")\n",
    "        calc = a3.Calculation(base_dir=path_dicts[method][system], stream_log_level=logging.CRITICAL)\n",
    "        total_cost_sys = 0\n",
    "        for leg in calc.legs:\n",
    "            leg_cost = costs[system][leg.leg_type.name.lower()] * REF_COST * leg.tot_simtime\n",
    "            total_cost_sys += leg_cost\n",
    "        total_costs[method][system] = total_cost_sys\n",
    "\n",
    "        calc._close_logging_handlers()\n",
    "        del(calc)\n",
    "\n",
    "        with open(\"final_analysis/total_costs.pkl\", \"wb\") as f:\n",
    "            pickle.dump(total_costs, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Alibay results\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from scipy.stats import sem, t\n",
    "\n",
    "def get_95_ci(data: np.ndarray) -> Tuple[float, float]:\n",
    "    \"\"\"Get the 95% confidence interval for a given array of data using scipy.stats.sem\"\"\"\n",
    "    mean_free_energy = np.mean(data)\n",
    "    conf_int = t.interval(\n",
    "        0.95,\n",
    "        len(data) - 1,\n",
    "        mean_free_energy,\n",
    "        scale=sem(data),\n",
    "    )[1] - mean_free_energy # 95 % C.I.\n",
    "    return conf_int\n",
    "\n",
    "alibay_results = pd.read_csv(\"final_analysis/alibay_results.csv\", index_col=0)\n",
    "\n",
    "# Cyclod ligands we want\n",
    "cyclod_ligs = [\"2\", \"3\", \"4\", \"8\", \"14\", \"16\", \"27\", \"39\", \"40\"]\n",
    "\n",
    "# Save a dict of overall results\n",
    "overall_results_alibay = {}\n",
    "for lig in cyclod_ligs:\n",
    "    overall_results_alibay[lig] = {}\n",
    "    dgs = alibay_results.loc[alibay_results[\"ligand_ID\"] == lig, \"calc_dG\"].values\n",
    "    mean_dgs = np.mean(dgs)\n",
    "    ci_95 = get_95_ci(dgs)\n",
    "    overall_results_alibay[lig][\"mean_dG\"] = mean_dgs\n",
    "    overall_results_alibay[lig][\"95_ci\"] = ci_95\n",
    "\n",
    "with open(\"final_analysis/overall_results_alibay.pkl\", \"wb\") as f:\n",
    "    pickle.dump(overall_results_alibay, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restraint corrections and restraint parameters\n",
    "\n",
    "import a3fe as a3\n",
    "import pickle\n",
    "\n",
    "ligs = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "# Get the restraint corrections for each system\n",
    "restraint_corrections = {}\n",
    "restraint_dicts = {}\n",
    "for lig in ligs:\n",
    "    print(f\"Analysing {lig}\")\n",
    "    calc = a3.Calculation(base_dir = ligs[lig])\n",
    "    restr_corr = calc.legs[0].restraints[0].getCorrection().value()\n",
    "    restraint_corrections[lig] = restr_corr\n",
    "    print(f\"Getting restraint parameters for {lig}\")\n",
    "    restr = calc.legs[0].restraints[0]\n",
    "    restr_dict = eval(calc.legs[0].restraints[0].toString(\"SOMD\").split(\"=\")[1])\n",
    "    restraint_dicts[lig] = restr_dict\n",
    "    calc._close_logging_handlers()\n",
    "    del(calc)\n",
    "\n",
    "with open(\"final_analysis/restraint_corrections.pkl\", \"wb\") as f:\n",
    "    pickle.dump(restraint_corrections, f)\n",
    "\n",
    "with open(\"final_analysis/restraint_dicts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(restraint_dicts, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lambda values\n",
    "\n",
    "import a3fe as a3\n",
    "import pickle\n",
    "\n",
    "\n",
    "lam_vals = {}\n",
    "for lig in ligs:\n",
    "    print(f\"Analysing {lig}\")\n",
    "    lam_vals[lig] = {}\n",
    "    calc = a3.Calculation(base_dir = ligs[lig], stream_log_level=logging.CRITICAL)\n",
    "    for leg in calc.legs:\n",
    "        lam_vals[lig][str(leg.leg_type)] = {}\n",
    "        for stage in leg.stages:\n",
    "            lam_vals[lig][str(leg.leg_type)][str(stage.stage_type)] = stage.lam_vals\n",
    "    calc._close_logging_handlers()\n",
    "    del(calc)\n",
    "\n",
    "    # Write most recent version of the dictionary to a pickle\n",
    "    with open(\"final_analysis/lam_vals.pkl\", \"wb\") as f:\n",
    "        pickle.dump(lam_vals, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sampling times\n",
    "\n",
    "import a3fe as a3\n",
    "import pickle\n",
    "\n",
    "sampling_times_ns = {}\n",
    "for lig in ligs:\n",
    "    print(f\"Analysing {lig}\")\n",
    "    sampling_times_ns[lig] = {}\n",
    "    calc = a3.Calculation(base_dir = ligs[lig], stream_log_level=logging.CRITICAL)\n",
    "    for leg in calc.legs:\n",
    "        leg_str = str(leg.leg_type).split(\".\")[1].lower()\n",
    "        sampling_times_ns[lig][leg_str] = {}\n",
    "        for stage in leg.stages:\n",
    "            stage_str = str(stage.stage_type).split(\".\")[1].lower()\n",
    "            sampling_times_ns[lig][leg_str][stage_str] = {}\n",
    "            sampling_times_ns[lig][leg_str][stage_str][\"times\"] = [lam.tot_simtime for lam in stage.lam_windows]\n",
    "            sampling_times_ns[lig][leg_str][stage_str][\"times\"] = [lam.tot_simtime for lam in stage.lam_windows]\n",
    "            sampling_times_ns[lig][leg_str][stage_str][\"equil_times\"] = [lam.equil_time * lam.ensemble_size for lam in stage.lam_windows]\n",
    "            sampling_times_ns[lig][leg_str][stage_str][\"lam_vals\"] = [lam.lam for lam in stage.lam_windows]\n",
    "\n",
    "    calc._close_logging_handlers()\n",
    "    del(calc)\n",
    "\n",
    "    # Write most recent version of the dictionary to a pickle\n",
    "    with open(\"final_analysis/sampling_times.pkl\", \"wb\") as f:\n",
    "        pickle.dump(sampling_times_ns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sampling times for the non-adaptive runs\n",
    "import a3fe as a3\n",
    "import pickle\n",
    "\n",
    "ligs = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "adaptive_paths = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "non_adapt_paths = {lig: f\"../non_adaptive/{adapt_path}_5000ps\" for lig, adapt_path in adaptive_paths.items()}\n",
    "sampling_times_ns = {}\n",
    "for lig in ligs:\n",
    "    print(f\"Analysing {lig}\")\n",
    "    sampling_times_ns[lig] = {}\n",
    "    calc = a3.Calculation(base_dir = non_adapt_paths[lig], stream_log_level=logging.CRITICAL)\n",
    "    for leg in calc.legs:\n",
    "        leg_str = str(leg.leg_type).split(\".\")[1].lower()\n",
    "        sampling_times_ns[lig][leg_str] = {}\n",
    "        for stage in leg.stages:\n",
    "            stage_str = str(stage.stage_type).split(\".\")[1].lower()\n",
    "            sampling_times_ns[lig][leg_str][stage_str] = {}\n",
    "            sampling_times_ns[lig][leg_str][stage_str][\"times\"] = [lam.tot_simtime for lam in stage.lam_windows]\n",
    "            sampling_times_ns[lig][leg_str][stage_str][\"times\"] = [lam.tot_simtime for lam in stage.lam_windows]\n",
    "            sampling_times_ns[lig][leg_str][stage_str][\"equil_times\"] = [lam.equil_time * lam.ensemble_size for lam in stage.lam_windows]\n",
    "            sampling_times_ns[lig][leg_str][stage_str][\"lam_vals\"] = [lam.lam for lam in stage.lam_windows]\n",
    "\n",
    "    calc._close_logging_handlers()\n",
    "    del(calc)\n",
    "\n",
    "    # Write most recent version of the dictionary to a pickle\n",
    "    with open(\"final_analysis/sampling_times_nonadapt.pkl\", \"wb\") as f:\n",
    "        pickle.dump(sampling_times_ns, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import a3fe as a3\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "ligs = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "adaptive_paths = {\n",
    "    \"2\": \"lig_2\",\n",
    "    \"3\": \"lig_3\",\n",
    "    \"4\": \"lig_4\",\n",
    "    \"8\": \"lig_8\",\n",
    "    \"14\": \"lig_14\",\n",
    "    \"16\": \"lig_16\",\n",
    "    \"27\": \"lig_27\",\n",
    "    \"39\": \"lig_39_cry_pose\",\n",
    "    \"40\": \"lig_40\",\n",
    "}\n",
    "\n",
    "non_adapt_paths = {lig: f\"../non_adaptive/{adapt_path}_5000ps\" for lig, adapt_path in adaptive_paths.items()}\n",
    "\n",
    "# Code to generate dictionary of 100 blocks of free energy changes for each stage for each leg for each time for each system\n",
    "for method in [\"adaptive\", \"non_adaptive\"]:\n",
    "    paths = adaptive_paths if method == \"adaptive\" else non_adapt_paths\n",
    "    # If there is already a pickle, load it\n",
    "    try:\n",
    "        with open(f\"final_analysis/dgs_conv_{method}_nonequil.pkl\", \"rb\") as f:\n",
    "            dgs_conv = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        dgs_conv = {}\n",
    "    for lig in ligs:\n",
    "        if lig in dgs_conv:\n",
    "            continue\n",
    "        dgs_conv[lig] = {}\n",
    "        print(f\"Analysing {lig}\")\n",
    "        calc = a3.Calculation(base_dir = paths[lig], stream_log_level=logging.CRITICAL)\n",
    "        for leg in calc.legs:\n",
    "            dgs_conv[lig][str(leg.leg_type)] = {}\n",
    "            for stage in leg.stages:\n",
    "                dgs_conv[lig][str(leg.leg_type)][str(stage.stage_type)] = {}\n",
    "                fracts, dgs = stage.analyse_convergence(mode=\"block\", equilibrated=False)\n",
    "                dgs_conv[lig][str(leg.leg_type)][str(stage.stage_type)][\"fracts\"] = fracts\n",
    "                dgs_conv[lig][str(leg.leg_type)][str(stage.stage_type)][\"dgs\"] = dgs\n",
    "        calc._close_logging_handlers()\n",
    "        del(calc)\n",
    "\n",
    "        # Write most recent version of the dictionary to a pickle\n",
    "        with open(f\"final_analysis/dgs_conv_{method}_nonequil.pkl\", \"wb\") as f:\n",
    "            pickle.dump(dgs_conv, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensequil",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
